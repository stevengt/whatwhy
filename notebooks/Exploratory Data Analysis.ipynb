{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install corenlp server by running:\n",
    "#    giveme5w1h-corenlp install\n",
    "# Start corenlp server by running:\n",
    "#    giveme5w1h-corenlp\n",
    "# corenlp does not work on new versions of Java. Install Java 8 in a conda environment with:\n",
    "#    conda install -c cidermole jdk8\n",
    "# Must add this caching file manually:\n",
    "#    mkdir -p ~/anaconda3/envs/CONDA_ENV_NAME/lib/python3.7/site-packages/Giveme5W1H/examples/caches\n",
    "#    cd ~/anaconda3/envs/CONDA_ENV_NAME/lib/python3.7/site-packages/Giveme5W1H/examples/caches\n",
    "#    wget https://github.com/fhamborg/Giveme5W1H/blob/master/Giveme5W1H/examples/caches/_Nominatim.prickle?raw=true\n",
    "#    mv _Nominatim.prickle\\?raw\\=true Nominatim.prickle\n",
    "# Must download the \"punkt\" tokenizer models for nltk:\n",
    "#    python -c \"import nltk; nltk.download('punkt')\"\n",
    "# Must download the \"en_core_web_sm\" models for SpaCY:\n",
    "#    https://github.com/explosion/spaCy\n",
    "#    python -m spacy download en_core_web_sm\n",
    "# Install dask:\n",
    "#    pip install \"dask[complete]\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading CSV file...\n",
      "INFO:root:Preprocessing text...\n",
      "INFO:root:Extracting 5w1h phrases from text...\n",
      "INFO:GiveMe5W:No extractors passed: initializing default configuration.\n",
      "INFO:GiveMe5W:/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/examples/caches/Nominatim.prickle entries: 14 size: 656.0 bytes\n",
      "INFO:GiveMe5W:No combinedScorers passed: initializing default configuration.\n",
      "INFO:GiveMe5W:No extractors passed: initializing default configuration.\n",
      "INFO:GiveMe5W:No combinedScorers passed: initializing default configuration.\n",
      "INFO:GiveMe5W:No extractors passed: initializing default configuration.\n",
      "INFO:GiveMe5W:No combinedScorers passed: initializing default configuration.\n",
      "INFO:GiveMe5W:No extractors passed: initializing default configuration.\n",
      "INFO:GiveMe5W:No combinedScorers passed: initializing default configuration.\n",
      "INFO:GiveMe5W:No extractors passed: initializing default configuration.\n",
      "INFO:GiveMe5W:No combinedScorers passed: initializing default configuration.\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/extractor/extractor.py\", line 20, in run\n",
      "    extractor.process(document)\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/extractor/extractors/abs_extractor.py\", line 40, in process\n",
      "    self._extract_candidates(document)\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/extractor/extractors/cause_extractor.py\", line 92, in _extract_candidates\n",
      "    for candidate in self._evaluate_tree(tree):\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/extractor/extractors/cause_extractor.py\", line 140, in _evaluate_tree\n",
      "    verb_synset = set(wordnet.synsets(normalized, 'v'))\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1584, in synsets\n",
      "    for p in pos\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1586, in <listcomp>\n",
      "    for offset in index[form].get(p, [])\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1382, in synset_from_pos_and_offset\n",
      "    synset = self._synset_from_pos_and_line(pos, data_file_line)\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1422, in _synset_from_pos_and_line\n",
      "    lexname_index = int(_next_token())\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1416, in _next_token\n",
      "    return next(_iter)\n",
      "StopIteration\n",
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/extractor/extractor.py\", line 20, in run\n",
      "    extractor.process(document)\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/extractor/extractors/abs_extractor.py\", line 40, in process\n",
      "    self._extract_candidates(document)\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/extractor/extractors/cause_extractor.py\", line 92, in _extract_candidates\n",
      "    for candidate in self._evaluate_tree(tree):\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/extractor/extractors/cause_extractor.py\", line 140, in _evaluate_tree\n",
      "    verb_synset = set(wordnet.synsets(normalized, 'v'))\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1584, in synsets\n",
      "    for p in pos\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1586, in <listcomp>\n",
      "    for offset in index[form].get(p, [])\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1383, in synset_from_pos_and_offset\n",
      "    assert synset._offset == offset\n",
      "AssertionError\n",
      "\n",
      "\n",
      "Exception in thread Thread-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/extractor/extractor.py\", line 20, in run\n",
      "    extractor.process(document)\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/extractor/extractors/abs_extractor.py\", line 40, in process\n",
      "    self._extract_candidates(document)\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/extractor/extractors/cause_extractor.py\", line 92, in _extract_candidates\n",
      "    for candidate in self._evaluate_tree(tree):\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/Giveme5W1H/extractor/extractors/cause_extractor.py\", line 173, in _evaluate_tree\n",
      "    noun_synset = set(wordnet.synsets(noun, 'n'))\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1584, in synsets\n",
      "    for p in pos\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1586, in <listcomp>\n",
      "    for offset in index[form].get(p, [])\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1382, in synset_from_pos_and_offset\n",
      "    synset = self._synset_from_pos_and_line(pos, data_file_line)\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1422, in _synset_from_pos_and_line\n",
      "    lexname_index = int(_next_token())\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1416, in _next_token\n",
      "    return next(_iter)\n",
      "StopIteration\n",
      "\n",
      "Process ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/code/whatwhy/whatwhy/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#tweets_csv_file = \"/home/zach/git/whatwhy/Tweets/all_tweets_aggregated.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtweets_csv_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/stevengt/Documents/code/whatwhy/Tweets/all_tweets_aggregated.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_df_with_keywords_from_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_csv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# print(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/whatwhy/whatwhy/main.py\u001b[0m in \u001b[0;36mget_df_with_keywords_from_csv\u001b[0;34m(filename, nrows)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mextractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeywordsExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdf_with_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_5w1h_keywords_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_with_keywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/whatwhy/whatwhy/keywords_extractor.py\u001b[0m in \u001b[0;36madd_5w1h_keywords_to_df\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_5w1h_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_raw_5w1h_texts_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_5w1h_keyword_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_words_from_5w1h_keyword_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/whatwhy/whatwhy/keywords_extractor.py\u001b[0m in \u001b[0;36madd_raw_5w1h_texts_to_df\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting 5w1h phrases from text...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_df_as_dask_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_partitions\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0madd_raw_5w1h_texts_to_dask_df_partition\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"processes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize_5w1h_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \"\"\"\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.7/site-packages/dask/multiprocessing.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, pool, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mpack_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpack_exception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mraise_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         )\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.7/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;31m# Main loop, wait on tasks to finish, insert new ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"waiting\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ready\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"running\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                     \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.7/site-packages/dask/local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 s, sys: 3.3 s, total: 24 s\n",
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/stevengt/anaconda3/envs/twitter/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%time %run -i \"/home/stevengt/Documents/code/whatwhy/whatwhy/main.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"/home/stevengt/Documents/code/whatwhy/notebooks/opinion parser.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Opinion Terms\"] = df[\"Preprocessed Text\"].apply( get_opinion_terms_from_text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# print(df[[\"Preprocessed Text\", \"Opinion Terms\"]])\n",
    "# df[\"What Raw Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source Name</th>\n",
       "      <th>Source URL</th>\n",
       "      <th>Preprocessed Text</th>\n",
       "      <th>Who Raw Text</th>\n",
       "      <th>What Raw Text</th>\n",
       "      <th>When Raw Text</th>\n",
       "      <th>Where Raw Text</th>\n",
       "      <th>Why Raw Text</th>\n",
       "      <th>How Raw Text</th>\n",
       "      <th>Who Keywords</th>\n",
       "      <th>What Keywords</th>\n",
       "      <th>When Keywords</th>\n",
       "      <th>Where Keywords</th>\n",
       "      <th>Why Keywords</th>\n",
       "      <th>How Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10538487904</td>\n",
       "      <td>Ok today I have to find something to wear for ...</td>\n",
       "      <td>Cheng-Caverlee-Lee</td>\n",
       "      <td>https://archive.org/details/twitter_cikm_2010</td>\n",
       "      <td>Ok today I have to find something to wear for ...</td>\n",
       "      <td>I</td>\n",
       "      <td>have to find something</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>I</td>\n",
       "      <td>Ok today I have to find something to wear for</td>\n",
       "      <td>[i]</td>\n",
       "      <td>[something, have, to, find]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i]</td>\n",
       "      <td>[something, to, i, find, wear, have, for, ok, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10536835844</td>\n",
       "      <td>I am glad I'm having this show but I can't wai...</td>\n",
       "      <td>Cheng-Caverlee-Lee</td>\n",
       "      <td>https://archive.org/details/twitter_cikm_2010</td>\n",
       "      <td>I am glad I'm having this show but I can't wai...</td>\n",
       "      <td>I</td>\n",
       "      <td>am glad I</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>I</td>\n",
       "      <td>am glad I 'm having this show but I ca</td>\n",
       "      <td>[i]</td>\n",
       "      <td>[am glad, i]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i]</td>\n",
       "      <td>[thi, i, ca, show, but, am glad, having, 'm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10536809086</td>\n",
       "      <td>Honestly I don't even know what's going on any...</td>\n",
       "      <td>Cheng-Caverlee-Lee</td>\n",
       "      <td>https://archive.org/details/twitter_cikm_2010</td>\n",
       "      <td>Honestly I don't even know what's going on any...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Honestly I do n't even know what 's going on</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i, going, n't, know, honestly, do, even, on, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10534149786</td>\n",
       "      <td>@LovelyJ_Janelle hey sorry I'm sitting infront...</td>\n",
       "      <td>Cheng-Caverlee-Lee</td>\n",
       "      <td>https://archive.org/details/twitter_cikm_2010</td>\n",
       "      <td>hey sorry I'm sitting infront of this sewing m...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>I</td>\n",
       "      <td>hey sorry I 'm sitting infront of this sewing ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i]</td>\n",
       "      <td>[thi, sorry, i, of, sitting, infront, 'm, hey,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10530203659</td>\n",
       "      <td>Sitting infront of this sewing machine ... I d...</td>\n",
       "      <td>Cheng-Caverlee-Lee</td>\n",
       "      <td>https://archive.org/details/twitter_cikm_2010</td>\n",
       "      <td>Sitting infront of this sewing machine ... I d...</td>\n",
       "      <td>I</td>\n",
       "      <td>do n't feel like doing this</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>I</td>\n",
       "      <td>'m tired and feeling lazy .</td>\n",
       "      <td>[i]</td>\n",
       "      <td>[n't, thi, like, doing, do, feel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i]</td>\n",
       "      <td>[tired, lazy, feeling, and, 'm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>10325347098</td>\n",
       "      <td>Ok take off time ... Say a prayer for me ... S...</td>\n",
       "      <td>Cheng-Caverlee-Lee</td>\n",
       "      <td>https://archive.org/details/twitter_cikm_2010</td>\n",
       "      <td>Ok take off time ... Say a prayer for me ... S...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Ok take off time ... Say a prayer for me</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[time, say, off, prayer, for, ok, a, take, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>10325322832</td>\n",
       "      <td>@Jaydenonline thanky :)</td>\n",
       "      <td>Cheng-Caverlee-Lee</td>\n",
       "      <td>https://archive.org/details/twitter_cikm_2010</td>\n",
       "      <td>thanky :)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>thanky :) .</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[thanky :)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>10325066490</td>\n",
       "      <td>Imma need this man behind me to shut the hell ...</td>\n",
       "      <td>Cheng-Caverlee-Lee</td>\n",
       "      <td>https://archive.org/details/twitter_cikm_2010</td>\n",
       "      <td>Imma need this man behind me to shut the hell ...</td>\n",
       "      <td>me</td>\n",
       "      <td>have n't slept in 2 days</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Imma</td>\n",
       "      <td></td>\n",
       "      <td>[me]</td>\n",
       "      <td>[n't, have, in, slept, 2 days]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[imma]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>10324819870</td>\n",
       "      <td>I'm on the plane .. Finally!!!</td>\n",
       "      <td>Cheng-Caverlee-Lee</td>\n",
       "      <td>https://archive.org/details/twitter_cikm_2010</td>\n",
       "      <td>I'm on the plane .. Finally!!!</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Finally !!!</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[finally]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>10323236482</td>\n",
       "      <td>Omg I hate lines</td>\n",
       "      <td>Cheng-Caverlee-Lee</td>\n",
       "      <td>https://archive.org/details/twitter_cikm_2010</td>\n",
       "      <td>Omg I hate lines</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>I</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID                                               Text  \\\n",
       "0   10538487904  Ok today I have to find something to wear for ...   \n",
       "1   10536835844  I am glad I'm having this show but I can't wai...   \n",
       "2   10536809086  Honestly I don't even know what's going on any...   \n",
       "3   10534149786  @LovelyJ_Janelle hey sorry I'm sitting infront...   \n",
       "4   10530203659  Sitting infront of this sewing machine ... I d...   \n",
       "..          ...                                                ...   \n",
       "95  10325347098  Ok take off time ... Say a prayer for me ... S...   \n",
       "96  10325322832                            @Jaydenonline thanky :)   \n",
       "97  10325066490  Imma need this man behind me to shut the hell ...   \n",
       "98  10324819870                     I'm on the plane .. Finally!!!   \n",
       "99  10323236482                                   Omg I hate lines   \n",
       "\n",
       "           Source Name                                     Source URL  \\\n",
       "0   Cheng-Caverlee-Lee  https://archive.org/details/twitter_cikm_2010   \n",
       "1   Cheng-Caverlee-Lee  https://archive.org/details/twitter_cikm_2010   \n",
       "2   Cheng-Caverlee-Lee  https://archive.org/details/twitter_cikm_2010   \n",
       "3   Cheng-Caverlee-Lee  https://archive.org/details/twitter_cikm_2010   \n",
       "4   Cheng-Caverlee-Lee  https://archive.org/details/twitter_cikm_2010   \n",
       "..                 ...                                            ...   \n",
       "95  Cheng-Caverlee-Lee  https://archive.org/details/twitter_cikm_2010   \n",
       "96  Cheng-Caverlee-Lee  https://archive.org/details/twitter_cikm_2010   \n",
       "97  Cheng-Caverlee-Lee  https://archive.org/details/twitter_cikm_2010   \n",
       "98  Cheng-Caverlee-Lee  https://archive.org/details/twitter_cikm_2010   \n",
       "99  Cheng-Caverlee-Lee  https://archive.org/details/twitter_cikm_2010   \n",
       "\n",
       "                                    Preprocessed Text Who Raw Text  \\\n",
       "0   Ok today I have to find something to wear for ...            I   \n",
       "1   I am glad I'm having this show but I can't wai...            I   \n",
       "2   Honestly I don't even know what's going on any...                \n",
       "3   hey sorry I'm sitting infront of this sewing m...                \n",
       "4   Sitting infront of this sewing machine ... I d...            I   \n",
       "..                                                ...          ...   \n",
       "95  Ok take off time ... Say a prayer for me ... S...                \n",
       "96                                          thanky :)                \n",
       "97  Imma need this man behind me to shut the hell ...           me   \n",
       "98                     I'm on the plane .. Finally!!!                \n",
       "99                                   Omg I hate lines                \n",
       "\n",
       "                  What Raw Text When Raw Text Where Raw Text Why Raw Text  \\\n",
       "0        have to find something                                         I   \n",
       "1                     am glad I                                         I   \n",
       "2                                                                           \n",
       "3                                                                       I   \n",
       "4   do n't feel like doing this                                         I   \n",
       "..                          ...           ...            ...          ...   \n",
       "95                                                                          \n",
       "96                                                                          \n",
       "97     have n't slept in 2 days                                      Imma   \n",
       "98                                                                          \n",
       "99                                                                      I   \n",
       "\n",
       "                                         How Raw Text Who Keywords  \\\n",
       "0       Ok today I have to find something to wear for          [i]   \n",
       "1              am glad I 'm having this show but I ca          [i]   \n",
       "2        Honestly I do n't even know what 's going on           []   \n",
       "3   hey sorry I 'm sitting infront of this sewing ...           []   \n",
       "4                         'm tired and feeling lazy .          [i]   \n",
       "..                                                ...          ...   \n",
       "95           Ok take off time ... Say a prayer for me           []   \n",
       "96                                        thanky :) .           []   \n",
       "97                                                            [me]   \n",
       "98                                        Finally !!!           []   \n",
       "99                                                              []   \n",
       "\n",
       "                        What Keywords When Keywords Where Keywords  \\\n",
       "0         [something, have, to, find]            []             []   \n",
       "1                        [am glad, i]            []             []   \n",
       "2                                  []            []             []   \n",
       "3                                  []            []             []   \n",
       "4   [n't, thi, like, doing, do, feel]            []             []   \n",
       "..                                ...           ...            ...   \n",
       "95                                 []            []             []   \n",
       "96                                 []            []             []   \n",
       "97     [n't, have, in, slept, 2 days]            []             []   \n",
       "98                                 []            []             []   \n",
       "99                                 []            []             []   \n",
       "\n",
       "   Why Keywords                                       How Keywords  \n",
       "0           [i]  [something, to, i, find, wear, have, for, ok, ...  \n",
       "1           [i]       [thi, i, ca, show, but, am glad, having, 'm]  \n",
       "2            []  [i, going, n't, know, honestly, do, even, on, ...  \n",
       "3           [i]  [thi, sorry, i, of, sitting, infront, 'm, hey,...  \n",
       "4           [i]                    [tired, lazy, feeling, and, 'm]  \n",
       "..          ...                                                ...  \n",
       "95           []     [time, say, off, prayer, for, ok, a, take, me]  \n",
       "96           []                                        [thanky :)]  \n",
       "97       [imma]                                                 []  \n",
       "98           []                                          [finally]  \n",
       "99          [i]                                                 []  \n",
       "\n",
       "[100 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
